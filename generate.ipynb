{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd9b257",
   "metadata": {},
   "source": [
    "# Generate Promo Codes (12‑char) with Letter/Digit Rules → CSV / Excel\n",
    "\n",
    "This notebook generates **unique** promo codes with configurable rules and writes them to\n",
    "a CSV file (streaming) and an Excel file. It uses cryptographically secure randomness.\n",
    "\n",
    "**Quick start:**\n",
    "1. Run the first two cells to install/import deps and set your rules.\n",
    "2. Run the main generation cell.\n",
    "3. Files will be created in the working directory.\n",
    "\n",
    "### What \"certain letter requirements\" can I enforce?\n",
    "- Minimum counts for letters and digits\n",
    "- Allowed character set (e.g., A–Z + 0–9, excluding ambiguous characters)\n",
    "- Must include at least one char from specific sets (e.g., must contain one of AEIOU)\n",
    "- Optional prefix/suffix\n",
    "- Forbid patterns via regular expressions (e.g., no three repeats, no specific substrings)\n",
    "\n",
    "You can tweak the CONFIG block below.\n",
    "\n",
    "%%\n",
    "(Optional) If running on a very minimal environment, uncomment to ensure pandas/openpyxl are present.\\\n",
    "%pip install -q pandas openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0dbb5",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98323645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3a1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "from secrets import choice as secure_choice\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6edb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = \"promo_codes.csv\"\n",
    "OUTPUT_XLSX = \"promo_codes.xlsx\"\n",
    "TOTAL_CODES = 1200000\n",
    "CODE_LENGTH = 12\n",
    "\n",
    "# All codes must start with this prefix\n",
    "PREFIX = \"TURMP\"\n",
    "SUFFIX = \"\"\n",
    "\n",
    "# Allowed chars AFTER the prefix\n",
    "ALPHABET_STR = \"23456789ABCDEFGHJKMNPQRSTUVWXYZabcdefghjkmnpqrstuvwxyz\"\n",
    "ALPHABET = list(ALPHABET_STR)\n",
    "\n",
    "# Disable extra composition rules (not requested)\n",
    "MIN_LETTERS = None\n",
    "MIN_DIGITS = None\n",
    "REQUIRE_ONE_OF = set()\n",
    "FORBIDDEN_REGEXES = []  # no extra forbids\n",
    "\n",
    "# Uniqueness backend\n",
    "UNIQUENESS_BACKEND = \"sqlite\"  # \"memory\" or \"sqlite\"\n",
    "SQLITE_DB_PATH = \"promo_codes_unique.db\"\n",
    "SQLITE_TABLE = \"codes\"\n",
    "\n",
    "# Excel writing\n",
    "SHEET_NAME = \"codes\"\n",
    "COL_A_HEADER = \"codes_1m\"\n",
    "COL_B_HEADER = \"codes_200k\"\n",
    "FIRST_COLUMN_TARGET = 1_000_000\n",
    "SECOND_COLUMN_TARGET = TOTAL_CODES - FIRST_COLUMN_TARGET  # 200,000\n",
    "EXCEL_CHUNK_SIZE = 100000  # number of rows per write flush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca2024",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ad88bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_letter_re = re.compile(r\"[A-Za-z]\")\n",
    "_digit_re = re.compile(r\"[0-9]\")\n",
    "_forbidden_res = [re.compile(p) for p in FORBIDDEN_REGEXES]\n",
    "\n",
    "\n",
    "def passes_rules(code: str) -> bool:\n",
    "    \"\"\"Return True if the code meets all configured rules (mostly disabled here).\"\"\"\n",
    "    if PREFIX and not code.startswith(PREFIX):\n",
    "        return False\n",
    "    if SUFFIX and not code.endswith(SUFFIX):\n",
    "        return False\n",
    "\n",
    "    core = code[len(PREFIX) : len(code) - len(SUFFIX) if SUFFIX else None]\n",
    "\n",
    "    # Optional rules (disabled)\n",
    "    if MIN_LETTERS is not None and len(_letter_re.findall(core)) < MIN_LETTERS:\n",
    "        return False\n",
    "    if MIN_DIGITS is not None and len(_digit_re.findall(core)) < MIN_DIGITS:\n",
    "        return False\n",
    "    if REQUIRE_ONE_OF and not any(ch in REQUIRE_ONE_OF for ch in core):\n",
    "        return False\n",
    "    for rx in _forbidden_res:\n",
    "        if rx.search(core):\n",
    "            return False\n",
    "\n",
    "    # Ensure ONLY allowed characters are used in the body\n",
    "    if not all(ch in ALPHABET for ch in core):\n",
    "        return False\n",
    "\n",
    "    # Length check\n",
    "    if len(code) != CODE_LENGTH:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def random_code() -> str:\n",
    "    body_len = CODE_LENGTH - len(PREFIX) - len(SUFFIX)\n",
    "    if body_len <= 0:\n",
    "        raise ValueError(\"CODE_LENGTH too small for given PREFIX/SUFFIX\")\n",
    "    body = \"\".join(secure_choice(ALPHABET) for _ in range(body_len))\n",
    "    return f\"{PREFIX}{body}{SUFFIX}\"\n",
    "\n",
    "\n",
    "class UniqueSink:\n",
    "    \"\"\"Track uniqueness either in memory or via SQLite.\"\"\"\n",
    "\n",
    "    def __init__(self, backend: str = \"memory\"):\n",
    "        self.backend = backend\n",
    "        if backend == \"memory\":\n",
    "            self._seen = set()\n",
    "        elif backend == \"sqlite\":\n",
    "            self._conn = sqlite3.connect(SQLITE_DB_PATH)\n",
    "            cur = self._conn.cursor()\n",
    "            cur.execute(\n",
    "                f\"CREATE TABLE IF NOT EXISTS {SQLITE_TABLE} (code TEXT PRIMARY KEY)\"\n",
    "            )\n",
    "            self._conn.commit()\n",
    "        else:\n",
    "            raise ValueError(\"backend must be 'memory' or 'sqlite'\")\n",
    "\n",
    "    def add_if_new(self, code: str) -> bool:\n",
    "        if self.backend == \"memory\":\n",
    "            if code in self._seen:\n",
    "                return False\n",
    "            self._seen.add(code)\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                cur = self._conn.cursor()\n",
    "                cur.execute(f\"INSERT INTO {SQLITE_TABLE}(code) VALUES (?)\", (code,))\n",
    "                self._conn.commit()\n",
    "                return True\n",
    "            except sqlite3.IntegrityError:\n",
    "                return False\n",
    "\n",
    "    def close(self):\n",
    "        if self.backend == \"sqlite\":\n",
    "            self._conn.close()\n",
    "\n",
    "\n",
    "# Remove old outputs\n",
    "for p in [OUTPUT_CSV, OUTPUT_XLSX, SQLITE_DB_PATH]:\n",
    "    if os.path.exists(p):\n",
    "        os.remove(p)\n",
    "\n",
    "unique = UniqueSink(UNIQUENESS_BACKEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baabb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open(OUTPUT_CSV, \"w\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"code\"])\n",
    "\n",
    "# Excel: pre-create workbook with both headers in one row\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=\"w\") as xw:\n",
    "    pd.DataFrame(columns=[COL_A_HEADER, COL_B_HEADER]).to_excel(\n",
    "        xw, index=False, sheet_name=SHEET_NAME\n",
    "    )\n",
    "\n",
    "# Track how many rows written to each Excel column so far\n",
    "excel_rows_written_A = (\n",
    "    0  # below header; data starts at row 2 in Excel, but we count data rows only\n",
    ")\n",
    "excel_rows_written_B = 0\n",
    "\n",
    "# Buffers to flush in chunks\n",
    "buffer_A = []  # for the first 1,000,000 codes\n",
    "buffer_B = []  # for the remaining 200,000 codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6ef8d",
   "metadata": {},
   "source": [
    "## Main generation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1505be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Codes: 100%|██████████| 1200000/1200000 [23:51<00:00, 838.49code/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 1,200,000 unique codes to promo_codes.csv and promo_codes.xlsx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=TOTAL_CODES, desc=\"Generating Codes\", unit=\"code\") as pbar:\n",
    "    written_total = 0\n",
    "    while written_total < TOTAL_CODES:\n",
    "        code = random_code()\n",
    "        if not passes_rules(code):\n",
    "            continue\n",
    "        if not unique.add_if_new(code):\n",
    "            continue\n",
    "\n",
    "        csv_writer.writerow([code])\n",
    "\n",
    "        if written_total < FIRST_COLUMN_TARGET:\n",
    "            buffer_A.append(code)\n",
    "            if len(buffer_A) >= EXCEL_CHUNK_SIZE or (\n",
    "                written_total + 1 == FIRST_COLUMN_TARGET\n",
    "            ):\n",
    "                dfA = pd.DataFrame({COL_A_HEADER: buffer_A})\n",
    "                with pd.ExcelWriter(\n",
    "                    OUTPUT_XLSX, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\"\n",
    "                ) as xw:\n",
    "                    dfA.to_excel(\n",
    "                        xw,\n",
    "                        index=False,\n",
    "                        header=False,\n",
    "                        sheet_name=SHEET_NAME,\n",
    "                        startrow=1 + excel_rows_written_A,\n",
    "                        startcol=0,\n",
    "                    )\n",
    "                excel_rows_written_A += len(buffer_A)\n",
    "                buffer_A.clear()\n",
    "        else:\n",
    "            buffer_B.append(code)\n",
    "            if len(buffer_B) >= EXCEL_CHUNK_SIZE or (written_total + 1 == TOTAL_CODES):\n",
    "                dfB = pd.DataFrame({COL_B_HEADER: buffer_B})\n",
    "                with pd.ExcelWriter(\n",
    "                    OUTPUT_XLSX, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\"\n",
    "                ) as xw:\n",
    "                    dfB.to_excel(\n",
    "                        xw,\n",
    "                        index=False,\n",
    "                        header=False,\n",
    "                        sheet_name=SHEET_NAME,\n",
    "                        startrow=1 + excel_rows_written_B,\n",
    "                        startcol=1,\n",
    "                    )\n",
    "                excel_rows_written_B += len(buffer_B)\n",
    "                buffer_B.clear()\n",
    "\n",
    "        written_total += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "# ---------- CLEANUP ----------\n",
    "unique.close()\n",
    "csv_file.close()\n",
    "\n",
    "print(f\"Done. Wrote {written_total:,} unique codes to {OUTPUT_CSV} and {OUTPUT_XLSX}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
